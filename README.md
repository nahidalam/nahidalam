# ğŸ‘‹ Hi, this is Nahid. I am an independent researcher with Cohere Labs community, working on Multimodal Learning, Computer Vision and Embodied AI. 

I recently created [Maya](https://github.com/nahidalam/maya) â€“ a multilingual multimodal LLM. I work at the intersection of **multimodal learning, computer vision and embodied ai**, developing models that perceive, reason, and act in the physical world.  
My current interests include:
- **Spatial understanding in VLMs** for real-world perception  
- **Physics-aware world models**  
- **Multimodal Learning**  
- **Simulation and Embodied AI** 


## Publications

- **Behind Maya: Building a Multilingual Vision-Language Model.**  
  Nahid Alam *et al.* CVPR 2025 Workshop (VLMs4All).  
  [arXiv](https://arxiv.org/abs/2505.08910) Â· [Google Scholar](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=11XdYBUAAAAJ&citation_for_view=11XdYBUAAAAJ:zYLM7Y9cAGgC)

- **Understanding and Mitigating Toxicity in Image-Text Pretraining Datasets: A Case Study on LLaVA.**  
  Nahid Alam, Karthik Reddy Kanjula, Surya Guthikonda, Shayekh Islam.  
  CVPR 2025 Workshop (ReGenAI), **Oral**.  
  [arXiv](https://arxiv.org/abs/2505.06356) Â· [Google Scholar](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=11XdYBUAAAAJ&citation_for_view=11XdYBUAAAAJ:Y0pCki6q_DkC)

- **Embedding Geometries of Contrastive Language-Image Pre-Training.**  
  Jason Chuan-Chih Chou, Nahid Alam. ECCV 2024 Workshop (Beyond Euclidean).  
  [arXiv](https://arxiv.org/abs/2409.13079) Â· [Google Scholar](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=11XdYBUAAAAJ&citation_for_view=11XdYBUAAAAJ:UeHWp8X0CEIC)

More at [Google Scholar](https://scholar.google.com/citations?hl=en&user=11XdYBUAAAAJ&view_op=list_works&sortby=pubdate)

---

### Recent Projects
- **[Maya](https://github.com/nahidalam/maya):** Multilingual multimodal foundation model (2 CVPR workshops)  
- **[Gemma3n-VLA](https://github.com/nahidalam/lerobot/tree/gemma3vla):** Vision-Language-Action model built with Hugging Face LeRobot  
- **[GR00T-N1 Hackathon](https://www.linkedin.com/feed/update/urn:li:activity:7309971614912167936/):** Bimanual robot manipulation with multimodal control  

---

### ğŸŒ Connect
- **LinkedIn:** [nahidalam](https://www.linkedin.com/in/nahidalam/)  
- **Twitter / X:** [@nahidalam](https://twitter.com/nahidalam)  
- **Email:** [your.email@domain.com](mailto:your.email@domain.com)  

---

> â€œBuilding world models that not only see but understand why things happen.â€

